{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b480ffc24243a68f3aaa97f669e3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allam_model = AutoModelForCausalLM.from_pretrained(\"model\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": \"كيف أجهز كوب شاهي؟\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~15GB Ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] كيف أجهز كوب شاهي؟ [/INST] لإعداد كوب من الشاي اللذيذ، يمكنك اتباع الخطوات التالية:\n",
      "\n",
      "المكونات:\n",
      "1. شاي أسود (حسب الرغبة والكمية المطلوبة)\n",
      "2. ماء (حسب الحاجة)\n",
      "3. سكر أو عسل (حسب الذوق)\n",
      "4. حليب (اختياري)\n",
      "5. أوراق النعناع (اختياري)\n",
      "\n",
      "الخطوات:\n",
      "1. املأ غلاية الشاي بالماء الطازج والغليان واتركها حتى تغلي.\n",
      "2. ضع كمية الشاي الأسود المطلوبة في مصفاة الشاي أو كيس شاي.\n",
      "3. إذا كنت تستخدم مصفاة الشاي، ضعها داخل الكوب الذي تريد تقديم الشاي فيه.\n",
      "4. إذا كنت تستخدم كيس شاي، ضعه مباشرة في الكوب.\n",
      "5. صب الماء المغلي فوق الشاي واتركه ينقع لمدة 2-5 دقائق (حسب الرغبة في قوة الشاي).\n",
      "6. بعد انتهاء النقع، إذا رغبت في إضافة الحليب، ضعه في كوب منفصل وأضف السكر أو العسل حسب الذوق.\n",
      "7. قلب الحليب والسكر حتى يذوب السكر تمامًا.\n",
      "8. صب الحليب المحلى فوق الشاي واتركه يمتزج جيدًا.\n",
      "9. إذا أردت نكهة النعناع، أضف أوراق النعناع الطازجة إلى الكوب وقلبها مع الشاي قبل إضافة الحليب والسكر.\n",
      "10. يمكنك تعديل كمية الشاي والماء والحليب والسكر حسب تفضيلك الشخصي.\n",
      "11. استمتع بكوب الشاي المحضر حديثًا.\n",
      "\n",
      "تذكر أن تعدل مدة النقع وكمية الشاي والماء والحليب والسكر حسب رغبتك الشخصية وقوة الشاي التي تفضلها. \n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "inputs = tokenizer(inputs, return_tensors='pt', return_token_type_ids=False)\n",
    "inputs = {k: v.to('cuda') for k,v in inputs.items()}\n",
    "# allam_model = allam_model.to('cuda')\n",
    "response = allam_model.generate(**inputs, max_new_tokens=4096, do_sample=True, top_k=50, top_p=0.95, temperature=.6)\n",
    "print(tokenizer.batch_decode(response, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '</s>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.all_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁ترى', '▁راسي', '▁ما', '▁عاد', '▁يتحمل', '▁الغاز', 'ك']\n",
      "['▁واخر', 'تها', '▁يا', '▁زيد', '▁اتم', 'وت', 'ني', '▁وانا', '▁حي']\n",
      "['▁هنا', '▁يا', '▁واد', '▁انا', '▁جاي', '▁مشوار', '▁قوم', '▁يلا']\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"ترى راسي ما عاد يتحمل الغازك\"\n",
    "sentence2 = \"واخرتها يا زيد اتموتني وانا حي\"\n",
    "sentence3 = \"هنا يا واد انا جاي مشوار قوم يلا\"\n",
    "for sentence in [sentence1, sentence2, sentence3]:\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "إن المعرفة قوة، والعلم نور\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sentence_with_tashkeel = \"إِنَّ المَعرِفَةَ قُوَّةٌ، وَالعِلمُ نُورٌ\"\n",
    "tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "text_after_removing_tashkeel = re.sub(tashkeel, '', sentence_with_tashkeel)\n",
    "print(text_after_removing_tashkeel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Special Tokens\n",
    "- `<|Najdi|>` : Najdi Arabic\n",
    "- `<|Hijazi|>` : Hijazi Arabic\n",
    "- `<|Khaliji|>` : Khaliji Arabic\n",
    "- `<|MSA|>` : Modern Standard Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allam_tokenizer = AutoTokenizer.from_pretrained(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allam_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁<', '|', 'N', 'aj', 'di', '|', '>', '▁Speaker', '2', ':', '▁لان', '▁المنافسة', '▁الشديدة']\n"
     ]
    }
   ],
   "source": [
    "tokens = allam_tokenizer.tokenize(\"<|Najdi|> Speaker2: لان المنافسة الشديدة\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "added_tokens = allam_tokenizer.add_special_tokens({'additional_special_tokens': ['<|Najdi|>', '<|Hijazi|>', '<|Khaliji|>', '<|MSA|>']})\n",
    "print(added_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8faf7dd01849eba6abc1f298b39580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(64004, 4096)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allam_model = AutoModelForCausalLM.from_pretrained(\"model\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "allam_model.resize_token_embeddings(len(allam_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allam_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allam_tokenizer.save_pretrained('allam_v0')\n",
    "\n",
    "allam_model.save_pretrained('allam_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e926f5f93216477ca7ed940c7f49ddd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allam_model = AutoModelForCausalLM.from_pretrained(\"allam_v0\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "allam_tokenizer = AutoTokenizer.from_pretrained(\"allam_v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|Najdi|>', '▁Speaker', '2', ':', '▁لان', '▁المنافسة', '▁الشديدة']\n"
     ]
    }
   ],
   "source": [
    "tokens = allam_tokenizer.tokenize(\"<|Najdi|> Speaker2: لان المنافسة الشديدة\")\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
